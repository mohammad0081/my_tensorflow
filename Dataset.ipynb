{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Tensorflow Dataset API\n",
    "* Mohammad Hassan Heydari"
   ],
   "id": "af1b6ae7631e3a4c"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-01T22:56:42.355057Z",
     "start_time": "2024-07-01T22:56:36.788538Z"
    }
   },
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.2\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T22:57:27.287921Z",
     "start_time": "2024-07-01T22:57:25.465271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
    "\n",
    "for element in dataset:\n",
    "  print(element)"
   ],
   "id": "2e3e7a3c1385f884",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T22:59:25.128521Z",
     "start_time": "2024-07-01T22:59:25.096017Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = dataset.map(lambda x: x*2)\n",
    "print(list(dataset.as_numpy_iterator()))\n",
    "print(dataset)"
   ],
   "id": "89ef5d025ffe583f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 8, 12]\n",
      "<_MapDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**apply() method**\n",
    "* Applies a transformation function to this dataset.\n",
    "\n",
    "apply(\n",
    "    transformation_func\n",
    ") -> 'DatasetV2'"
   ],
   "id": "dd6e7a86fb7f3f45"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T23:05:08.033251Z",
     "start_time": "2024-07-01T23:05:07.989115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = tf.data.Dataset.range(100)\n",
    "\n",
    "def dataset_fn(ds):\n",
    "  return ds.filter(lambda x: x < 10)\n",
    "\n",
    "dataset = dataset.apply(dataset_fn)\n",
    "\n",
    "list(dataset.as_numpy_iterator())"
   ],
   "id": "6fcd00a5243843f3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**as_numpy_iterator() method**\n",
    "* Returns an iterator which converts all elements of the dataset to numpy.\n",
    "\n",
    "Use as_numpy_iterator to inspect the content of your dataset. To see element shapes and types, print dataset elements directly instead of using as_numpy_iterator"
   ],
   "id": "9b9a9ea347704dc9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T23:07:17.631362Z",
     "start_time": "2024-07-01T23:07:17.617872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
    "for element in dataset:\n",
    "  print(element)"
   ],
   "id": "a605f597c4a9b718",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T23:07:28.623250Z",
     "start_time": "2024-07-01T23:07:28.609875Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
    "for element in dataset.as_numpy_iterator():\n",
    "  print(element)"
   ],
   "id": "681f3bbd6f385033",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T23:08:36.866881Z",
     "start_time": "2024-07-01T23:08:36.854592Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\n",
    "\n",
    "print(dataset.as_numpy_iterator(), end = '\\n---\\n')\n",
    "print(list(dataset.as_numpy_iterator()))"
   ],
   "id": "24cd37a981c8ebb2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumpyIterator(iterator=<tensorflow.python.data.ops.iterator_ops.OwnedIterator object at 0x7f4efacab550>)\n",
      "---\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**batch() method**\n",
    "* Combines consecutive elements of this dataset into batches.\n",
    "\n",
    "batch (\n",
    "\n",
    "batch_size,\n",
    "    \n",
    "drop_remainder=False,\n",
    "    \n",
    "num_parallel_calls=None,\n",
    "    \n",
    "deterministic=None,\n",
    "    \n",
    "name=None\n",
    ") -> 'DatasetV2'\n"
   ],
   "id": "9448e3a7975e4318"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T23:14:45.020832Z",
     "start_time": "2024-07-01T23:14:44.987617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = tf.data.Dataset.range(8)\n",
    "dataset = dataset.batch(3)\n",
    "list(dataset.as_numpy_iterator())"
   ],
   "id": "5690537f5a5399b3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 2]), array([3, 4, 5]), array([6, 7])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**num_parallel_cells** and **AUTOTUNE** : A tf.int64 scalar tf.Tensor, representing the number of batches to compute asynchronously in parallel. If not specified, batches will be computed sequentially. If the value tf.data.AUTOTUNE is used, then the number of parallel calls is set dynamically based on available resources.",
   "id": "4ae67128a903acd4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**Note** : If your program requires data to have a statically known shape (e.g., when using XLA), you should use drop_remainder=True. Without drop_remainder=True the shape of the output dataset will have an unknown leading dimension due to the possibility of a smaller final batch",
   "id": "b1e22277f6fd3b40"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T23:15:04.397186Z",
     "start_time": "2024-07-01T23:15:04.378585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dataset = tf.data.Dataset.range(8)\n",
    "dataset = dataset.batch(3, drop_remainder=True)\n",
    "list(dataset.as_numpy_iterator())"
   ],
   "id": "87ff09ba05ff45d5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 1, 2]), array([3, 4, 5])]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
